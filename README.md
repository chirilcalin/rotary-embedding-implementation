# rotary-embedding-implementation


This is an implementation of a GPT-2 style transformer with rotary, rather than absolute, positional embedding. This implementation is built from scratch based on the 'Attention is All You Need' (Google 2017) publication, and the 'RoFormer' publication (Su et. al 2021).
